{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-NFyYBaZnNz4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import requests\n",
        "import zipfile\n",
        "import os\n",
        "import sys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IUzFjcO8nlmo"
      },
      "outputs": [],
      "source": [
        "# Define the paths\n",
        "dataset_url = \"https://github.com/skoltech-nlp/detox/releases/download/emnlp2021/filtered_paranmt.zip\"\n",
        "zip_file_path = \"dataset.zip\"\n",
        "csv_file_path, tsv_file_path = \"dataset.csv\", \"filtered.tsv\"\n",
        "\n",
        "# Download the ZIP file\n",
        "response = requests.get(dataset_url)\n",
        "if response.status_code == 200:\n",
        "    with open(zip_file_path, 'wb') as file:\n",
        "        file.write(response.content)\n",
        "else:\n",
        "    print(\"Attempt failed\")\n",
        "    exit()\n",
        "\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(\".\")\n",
        "\n",
        "dataset = pd.read_csv(\"filtered.tsv\", delimiter='\\t')\n",
        "dataset.to_csv(csv_file_path, index=False)\n",
        "\n",
        "# ZIP cleaning up\n",
        "os.remove(zip_file_path)\n",
        "os.remove(tsv_file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "LDxXTs0Hny3d",
        "outputId": "d5539ec4-f731-421e-e66d-e52e94f9dce3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Unnamed: 0                                          reference  \\\n",
              "419610      419610           It'll be the fall of Saigon if I'm late.   \n",
              "167521      167521  Cruisin', gunning the engine so loud, nerds wo...   \n",
              "252613      252613                           I am an adult, damn it!\"   \n",
              "312041      312041              I killed then, but I did not like it.   \n",
              "395031      395031                             He would have me dead.   \n",
              "\n",
              "                                              translation  similarity  \\\n",
              "419610                        if I'm late, she'll be hit.    0.714844   \n",
              "167521  just drive up and dial the engine so that the ...    0.671165   \n",
              "252613                                    I'm an adult! \"    0.765863   \n",
              "312041               I killed them, but I didn't like it.    0.920389   \n",
              "395031                           he would have wanted me.    0.701146   \n",
              "\n",
              "        lenght_diff   ref_tox   trn_tox  \n",
              "419610     0.317073  0.000104  0.838105  \n",
              "167521     0.039474  0.058586  0.952140  \n",
              "252613     0.360000  0.994764  0.000303  \n",
              "312041     0.026316  0.020455  0.963189  \n",
              "395031     0.080000  0.991558  0.000057  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ed5f3ef3-fbe2-430f-8366-43f5ddad3e30\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>reference</th>\n",
              "      <th>translation</th>\n",
              "      <th>similarity</th>\n",
              "      <th>lenght_diff</th>\n",
              "      <th>ref_tox</th>\n",
              "      <th>trn_tox</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>419610</th>\n",
              "      <td>419610</td>\n",
              "      <td>It'll be the fall of Saigon if I'm late.</td>\n",
              "      <td>if I'm late, she'll be hit.</td>\n",
              "      <td>0.714844</td>\n",
              "      <td>0.317073</td>\n",
              "      <td>0.000104</td>\n",
              "      <td>0.838105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>167521</th>\n",
              "      <td>167521</td>\n",
              "      <td>Cruisin', gunning the engine so loud, nerds wo...</td>\n",
              "      <td>just drive up and dial the engine so that the ...</td>\n",
              "      <td>0.671165</td>\n",
              "      <td>0.039474</td>\n",
              "      <td>0.058586</td>\n",
              "      <td>0.952140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>252613</th>\n",
              "      <td>252613</td>\n",
              "      <td>I am an adult, damn it!\"</td>\n",
              "      <td>I'm an adult! \"</td>\n",
              "      <td>0.765863</td>\n",
              "      <td>0.360000</td>\n",
              "      <td>0.994764</td>\n",
              "      <td>0.000303</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>312041</th>\n",
              "      <td>312041</td>\n",
              "      <td>I killed then, but I did not like it.</td>\n",
              "      <td>I killed them, but I didn't like it.</td>\n",
              "      <td>0.920389</td>\n",
              "      <td>0.026316</td>\n",
              "      <td>0.020455</td>\n",
              "      <td>0.963189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>395031</th>\n",
              "      <td>395031</td>\n",
              "      <td>He would have me dead.</td>\n",
              "      <td>he would have wanted me.</td>\n",
              "      <td>0.701146</td>\n",
              "      <td>0.080000</td>\n",
              "      <td>0.991558</td>\n",
              "      <td>0.000057</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ed5f3ef3-fbe2-430f-8366-43f5ddad3e30')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ed5f3ef3-fbe2-430f-8366-43f5ddad3e30 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ed5f3ef3-fbe2-430f-8366-43f5ddad3e30');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-fffcf978-2528-440b-aab7-0321db256c52\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fffcf978-2528-440b-aab7-0321db256c52')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-fffcf978-2528-440b-aab7-0321db256c52 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "dataset.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9S1z_5VxSNZR",
        "outputId": "01c23200-85d1-48af-aa73-898e1072e371"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'nlp-Text-De-toxification'...\n",
            "remote: Enumerating objects: 78, done.\u001b[K\n",
            "remote: Counting objects: 100% (78/78), done.\u001b[K\n",
            "remote: Compressing objects: 100% (68/68), done.\u001b[K\n",
            "remote: Total 78 (delta 29), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (78/78), 2.00 MiB | 4.60 MiB/s, done.\n",
            "Resolving deltas: 100% (29/29), done.\n"
          ]
        }
      ],
      "source": [
        "repo_dir = \"nlp-Text-De-toxification\"\n",
        "\n",
        "if os.path.exists(repo_dir):\n",
        "    print(f\"{repo_dir} already exists. Removing it...\\n\")\n",
        "    !rm -r {repo_dir}\n",
        "\n",
        "# Clone the repository from GitHub\n",
        "!git clone https://github.com/Goshmar/nlp-Text-De-toxification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ERpd9IHgSTIV",
        "outputId": "83af36c2-7e14-40eb-c970-1c17da24f744"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m677.4/677.4 kB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.8/400.8 kB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m92.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m788.5/788.5 kB\u001b[0m \u001b[31m62.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m51.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m508.7/508.7 kB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m49.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.8/48.8 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for fairseq (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sentencepiece (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gdown (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for mpld3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for importlib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pptree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dask 2023.8.1 requires importlib-metadata>=4.13.0, but you have importlib-metadata 3.10.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "! pip install -r nlp-Text-De-toxification/requirements.txt -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5-4iwSIWNSL",
        "outputId": "c8948364-e3a9-4dcb-8018-85f908f5b0f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/nlp-Text-De-toxification/src\n"
          ]
        }
      ],
      "source": [
        "def add_sys_path(p):\n",
        "    p = os.path.abspath(p)\n",
        "    print(p)\n",
        "    if p not in sys.path:\n",
        "        sys.path.append(p)\n",
        "\n",
        "# adding the path to the condebert code root\n",
        "add_sys_path('nlp-Text-De-toxification/src')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O-bgBU9xRb7e"
      },
      "outputs": [],
      "source": [
        "from importlib import reload\n",
        "\n",
        "sys.path.append('/content/nlp-Text-De-toxification/src/models')\n",
        "\n",
        "import condbert\n",
        "\n",
        "from condbert import CondBertRewriter\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VKbBvoyKSr7n"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertForMaskedLM\n",
        "import numpy as np\n",
        "import pickle\n",
        "from tqdm.auto import tqdm, trange"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LdixuMH2XBLR"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cpu')  # please change it to e.g. 'cuda:0' if you want to use a GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8lS4l4bXUtS",
        "outputId": "51f798fa-113a-4a7f-960a-d10583f4bca4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "BertForMaskedLM(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (cls): BertOnlyMLMHead(\n",
              "    (predictions): BertLMPredictionHead(\n",
              "      (transform): BertPredictionHeadTransform(\n",
              "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (transform_act_fn): GELUActivation()\n",
              "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      )\n",
              "      (decoder): Linear(in_features=768, out_features=30522, bias=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 110,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_name = 'bert-base-uncased'\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "model = BertForMaskedLM.from_pretrained(model_name)\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uAXiOUtWXgZn"
      },
      "outputs": [],
      "source": [
        "# Downloading vocab for CondBert model\n",
        "def load_words_from_file(file_path):\n",
        "    with open(file_path, \"r\") as file:\n",
        "        words = [line.strip() for line in file.readlines()]\n",
        "    return words\n",
        "\n",
        "vocab_root = \"nlp-Text-De-toxification/data/vocab_1/\"\n",
        "negative_words = load_words_from_file(vocab_root + \"negative-words.txt\")\n",
        "toxic_words = load_words_from_file(vocab_root + \"toxic_words.txt\")\n",
        "positive_words = load_words_from_file(vocab_root + \"positive-words.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b_e5gt1bbi1o"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open(vocab_root + 'word2coef.pkl', 'rb') as f:\n",
        "    word2coef = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WBh8nkWRdeuJ"
      },
      "outputs": [],
      "source": [
        "token_toxicities = []\n",
        "with open(vocab_root + 'token_toxicities.txt', 'r') as f:\n",
        "    for line in f.readlines():\n",
        "        token_toxicities.append(float(line))\n",
        "token_toxicities = np.array(token_toxicities)\n",
        "token_toxicities = np.maximum(0, np.log(1/(1/token_toxicities-1)))   # log odds ratio\n",
        "# discourage meaningless tokens\n",
        "for tok in ['.', ',', '-']:\n",
        "    token_toxicities[tokenizer.encode(tok)][1] = 3\n",
        "\n",
        "for tok in ['you']:\n",
        "    token_toxicities[tokenizer.encode(tok)][1] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jiICkTqCePgD"
      },
      "outputs": [],
      "source": [
        "reload(condbert)\n",
        "from condbert import CondBertRewriter\n",
        "\n",
        "editor = CondBertRewriter(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    device=device,\n",
        "    neg_words=negative_words,\n",
        "    pos_words=positive_words,\n",
        "    word2coef=word2coef,\n",
        "    token_toxicities=token_toxicities,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzIFoVyeilrg",
        "outputId": "e6b3fad6-0319-4fb5-ea81-da2490f87bb9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You are an idiot!\n",
            "you are an the !\n"
          ]
        }
      ],
      "source": [
        "print(editor.translate('You are an idiot!'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qh1CQsfDipfj"
      },
      "outputs": [],
      "source": [
        "editor = CondBertRewriter(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    device=device,\n",
        "    neg_words=negative_words,\n",
        "    pos_words=positive_words,\n",
        "    word2coef=word2coef,\n",
        "    token_toxicities=token_toxicities,\n",
        "    predictor=None,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MHtdGxm8i1uy"
      },
      "outputs": [],
      "source": [
        "import masked_token_predictor_bert\n",
        "reload(masked_token_predictor_bert)\n",
        "\n",
        "from masked_token_predictor_bert import MaskedTokenPredictorBert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBtw9lXpjbGT",
        "outputId": "b2f2b8bf-3fdf-435d-ac5f-72211df5fd46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "you are an old man !\n"
          ]
        }
      ],
      "source": [
        "predictor = MaskedTokenPredictorBert(model, tokenizer, max_len=250, device=device, label=0, contrast_penalty=0.0)\n",
        "editor.predictor = predictor\n",
        "\n",
        "def adjust_logits(logits, label):\n",
        "    return logits - editor.token_toxicities * 3\n",
        "\n",
        "predictor.logits_postprocessor = adjust_logits\n",
        "\n",
        "print(editor.replacement_loop('You are an idiot!', verbose=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H9FhnyxynlHR"
      },
      "outputs": [],
      "source": [
        "import choosers\n",
        "reload(choosers)\n",
        "from choosers import EmbeddingSimilarityChooser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1KgqjuZpoTma",
        "outputId": "94c8f0ca-4678-4e22-b8d0-cac206efa562"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-10-21 19:06:03,200 https://flair.informatik.hu-berlin.de/resources/embeddings/token/glove.gensim.vectors.npy not found in cache, downloading to /tmp/tmpel7taytu\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 160000128/160000128 [00:09<00:00, 17251325.61B/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-10-21 19:06:13,121 copying /tmp/tmpel7taytu to cache at /root/.flair/embeddings/glove.gensim.vectors.npy\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-10-21 19:06:13,861 removing temp file /tmp/tmpel7taytu\n",
            "2023-10-21 19:06:14,682 https://flair.informatik.hu-berlin.de/resources/embeddings/token/glove.gensim not found in cache, downloading to /tmp/tmp7etnzslu\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21494764/21494764 [00:01<00:00, 13851046.41B/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-10-21 19:06:16,890 copying /tmp/tmp7etnzslu to cache at /root/.flair/embeddings/glove.gensim\n",
            "2023-10-21 19:06:16,919 removing temp file /tmp/tmp7etnzslu\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "predictor = MaskedTokenPredictorBert(\n",
        "    model, tokenizer, max_len=250, device=device, label=0, contrast_penalty=0.0,\n",
        "    confuse_bert_args=True, # this argument deteriorates quality but is used for backward compatibility\n",
        ")\n",
        "editor.predictor = predictor\n",
        "\n",
        "def adjust_logits(logits, label=0):\n",
        "    return logits - editor.token_toxicities * 10\n",
        "\n",
        "predictor.logits_postprocessor = adjust_logits\n",
        "\n",
        "cho = EmbeddingSimilarityChooser(sim_coef=100, tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 585,
          "referenced_widgets": [
            "0ddec33b8f384e31bb788265e55144df",
            "f31966c715c746d99f47175e6a57be8f",
            "fea030c8b17f496d9017400c26194008",
            "d363cd73f6ff4aa89d8edea9e35d2e18",
            "a17aaab8baca4fefb6101612e1439c6a",
            "67a90ae072d34eb7a7be8d753dff618a",
            "8ecb0aa4fd21485daf9e8390c1412119",
            "1c8e18acf1094b398b38e5eefffca584",
            "8dd5b67dffdb41769a6c98d56ca94e79",
            "ae7e9ce9a4614c518ff1fccf87eb8e14",
            "41f95a27a0e042f4a1175be3f034b781"
          ]
        },
        "id": "cJT65vHpmcNJ",
        "outputId": "c68e827f-a94f-45a8-95d9-8bfccde1cd52"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0ddec33b8f384e31bb788265e55144df",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------\n",
            "Shut up, Nick. You'll hurt Coco Chanel's feelings.\n",
            "--> . up , \" \" . . \" . . ' ll . coco chanel ' s feelings .\n",
            "------\n",
            "\n",
            "\n",
            "------\n",
            "If what I felt had been an actual wound, I'd have been bleeding to death.\n",
            "--> if what i felt had been an actual i , i ' d have been i to \" . . .\n",
            "------\n",
            "\n",
            "\n",
            "------\n",
            "And that we became friends in the process... ...and learned some shit about life and stuff.\n",
            "--> and that we became friends in the process . . . . . . and learned some \" \" . about \" . . and stuff .\n",
            "------\n",
            "\n",
            "\n",
            "------\n",
            "You smell like a hobo.\n",
            "--> i i like a \" \" \" .\n",
            "------\n",
            "\n",
            "\n",
            "------\n",
            "I'd kill my first born for a caramel macchiato.\n",
            "--> i ' d \" . . \" . . first . \" . for a caramel macchiato .\n",
            "------\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for example in tqdm(dataset.sample(5)['reference']):\n",
        "    print(\"------\")\n",
        "    print(example)\n",
        "    print(\"-->\", editor.replacement_loop(example, verbose=False, chooser=cho, n_top=10, n_tokens=(1,2,3), n_units=1))\n",
        "    print(\"------\\n\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BHQlX9Z8mrya"
      },
      "outputs": [],
      "source": [
        "VOCAB_DIRNAME = 'vocabularies'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xf4vpJwLwTYx"
      },
      "outputs": [],
      "source": [
        "model_name = 'bert-base-uncased'\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_gm3L7UwURZ",
        "outputId": "a34458c4-414a-42f1-a9c2-5d1887568b07"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "model = BertForMaskedLM.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_66ehTvOwWvD"
      },
      "outputs": [],
      "source": [
        "model.to(device);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iayabULEw70n"
      },
      "outputs": [],
      "source": [
        "tox_corpus_path = '/content/nlp-Text-De-toxification/data/train_toxic.txt'\n",
        "norm_corpus_path = '/content/nlp-Text-De-toxification/data/train_normal.txt'\n",
        "\n",
        "if not os.path.exists(VOCAB_DIRNAME):\n",
        "    os.makedirs(VOCAB_DIRNAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQyuMMJjwcL1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import argparse\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from nltk import ngrams\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "\n",
        "\n",
        "\n",
        "class NgramSalienceCalculator():\n",
        "    def __init__(self, tox_corpus, norm_corpus, use_ngrams=False):\n",
        "        ngrams = (1, 3) if use_ngrams else (1, 1)\n",
        "        self.vectorizer = CountVectorizer(ngram_range=ngrams)\n",
        "\n",
        "        tox_count_matrix = self.vectorizer.fit_transform(tox_corpus)\n",
        "        self.tox_vocab = self.vectorizer.vocabulary_\n",
        "        self.tox_counts = np.sum(tox_count_matrix, axis=0)\n",
        "\n",
        "        norm_count_matrix = self.vectorizer.fit_transform(norm_corpus)\n",
        "        self.norm_vocab = self.vectorizer.vocabulary_\n",
        "        self.norm_counts = np.sum(norm_count_matrix, axis=0)\n",
        "\n",
        "    def salience(self, feature, attribute='tox', lmbda=0.5):\n",
        "        assert attribute in ['tox', 'norm']\n",
        "        if feature not in self.tox_vocab:\n",
        "            tox_count = 0.0\n",
        "        else:\n",
        "            tox_count = self.tox_counts[0, self.tox_vocab[feature]]\n",
        "\n",
        "        if feature not in self.norm_vocab:\n",
        "            norm_count = 0.0\n",
        "        else:\n",
        "            norm_count = self.norm_counts[0, self.norm_vocab[feature]]\n",
        "\n",
        "        if attribute == 'tox':\n",
        "            return (tox_count + lmbda) / (norm_count + lmbda)\n",
        "        else:\n",
        "            return (norm_count + lmbda) / (tox_count + lmbda)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EjD66B3rwdd9",
        "outputId": "d3bbf724-2cab-4a65-8240-51dc3e998ed1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "88645\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "c = Counter()\n",
        "\n",
        "for fn in [tox_corpus_path, norm_corpus_path]:\n",
        "    with open(fn, 'r') as corpus:\n",
        "        for line in corpus.readlines():\n",
        "            for tok in line.strip().split():\n",
        "                c[tok] += 1\n",
        "\n",
        "print(len(c))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4E1rVgyxIQn",
        "outputId": "bf55d6b2-50dc-4087-df74-8a45fa64dee7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "88645\n"
          ]
        }
      ],
      "source": [
        "vocab = {w for w, _ in c.most_common() if _ > 0}  # if we took words with > 1 occurences, vocabulary would be x2 smaller, but we'll survive this size\n",
        "print(len(vocab))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WutV2zOfxKb2"
      },
      "outputs": [],
      "source": [
        "with open(tox_corpus_path, 'r') as tox_corpus, open(norm_corpus_path, 'r') as norm_corpus:\n",
        "    corpus_tox = [' '.join([w if w in vocab else '<unk>' for w in line.strip().split()]) for line in tox_corpus.readlines()]\n",
        "    corpus_norm = [' '.join([w if w in vocab else '<unk>' for w in line.strip().split()]) for line in norm_corpus.readlines()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sy91uv-xxNe8"
      },
      "outputs": [],
      "source": [
        "neg_out_name = '/content/nlp-Text-De-toxification/data/vocab_1/negative-words.txt'\n",
        "pos_out_name = '/content/nlp-Text-De-toxification/data/vocab_1/positive-words.txt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G5EKs-etxWCG"
      },
      "outputs": [],
      "source": [
        "threshold = 4\n",
        "sc = NgramSalienceCalculator(corpus_tox, corpus_norm, False)\n",
        "seen_grams = set()\n",
        "\n",
        "with open(neg_out_name, 'w') as neg_out, open(pos_out_name, 'w') as pos_out:\n",
        "    for gram in set(sc.tox_vocab.keys()).union(set(sc.norm_vocab.keys())):\n",
        "        if gram not in seen_grams:\n",
        "            seen_grams.add(gram)\n",
        "            toxic_salience = sc.salience(gram, attribute='tox')\n",
        "            polite_salience = sc.salience(gram, attribute='norm')\n",
        "            if toxic_salience > threshold:\n",
        "                neg_out.writelines(f'{gram}\\n')\n",
        "            elif polite_salience > threshold:\n",
        "                pos_out.writelines(f'{gram}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tRY4KpNExX9A"
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import make_pipeline\n",
        "pipe = make_pipeline(CountVectorizer(), LogisticRegression(max_iter=1000))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8arw5744xbl0"
      },
      "outputs": [],
      "source": [
        "X_train = corpus_tox + corpus_norm\n",
        "y_train = [1] * len(corpus_tox) + [0] * len(corpus_norm)\n",
        "pipe.fit(X_train, y_train);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0mOoKaJxdN6",
        "outputId": "deec410f-f615-426d-d0d0-b8b9a4a9e2de"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(88519,)"
            ]
          },
          "execution_count": 158,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "coefs = pipe[1].coef_[0]\n",
        "coefs.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RF7t03VLxexa"
      },
      "outputs": [],
      "source": [
        "word2coef = {w: coefs[idx] for w, idx in pipe[0].vocabulary_.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E3kR8qTyxgN2"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open('/content/nlp-Text-De-toxification/data/vocab_1/word2coef.pkl', 'wb') as f:\n",
        "    pickle.dump(word2coef, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RD9YlyhVxqD4",
        "outputId": "4602432f-82c8-4cc8-e95e-d12a531c1346"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 135390/135390 [02:15<00:00, 998.73it/s]\n",
            "100%|██████████| 135390/135390 [01:37<00:00, 1387.27it/s]\n"
          ]
        }
      ],
      "source": [
        "from collections import defaultdict\n",
        "toxic_counter = defaultdict(lambda: 1)\n",
        "nontoxic_counter = defaultdict(lambda: 1)\n",
        "\n",
        "for text in tqdm(corpus_tox):\n",
        "    for token in tokenizer.encode(text):\n",
        "        toxic_counter[token] += 1\n",
        "for text in tqdm(corpus_norm):\n",
        "    for token in tokenizer.encode(text):\n",
        "        nontoxic_counter[token] += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iVrw4rOPxr0w"
      },
      "outputs": [],
      "source": [
        "token_toxicities = [toxic_counter[i] / (nontoxic_counter[i] + toxic_counter[i]) for i in range(len(tokenizer.vocab))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TdE95IpKxsTX"
      },
      "outputs": [],
      "source": [
        "with open('/content/nlp-Text-De-toxification/data/vocab_1/token_toxicities.txt', 'w') as f:\n",
        "    for t in token_toxicities:\n",
        "        f.write(str(t))\n",
        "        f.write('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qu1dt7Jix3HE",
        "outputId": "519ee0fb-b92a-4efc-bc69-aa1ead52c85a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-17d57021e77a>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/nlp-Text-De-toxification/data/vocab_1/negative-words.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnegative_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/nlp-Text-De-toxification/data/vocab_1/positive-words.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/nlp-Text-De-toxification/data/vocab_1/negative-words.txt'"
          ]
        }
      ],
      "source": [
        "with open('/content/nlp-Text-De-toxification/data/vocab_1/negative-words.txt', \"r\") as f:\n",
        "    s = f.readlines()\n",
        "negative_words = list(map(lambda x: x[:-1], s))\n",
        "\n",
        "with open('/content/nlp-Text-De-toxification/data/vocab_1/positive-words.txt', \"r\") as f:\n",
        "    s = f.readlines()\n",
        "positive_words = list(map(lambda x: x[:-1], s))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kCIE14Q8yJ6N"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open('/content/nlp-Text-De-toxification/data/vocab_1/word2coef.pkl', 'rb') as f:\n",
        "    word2coef = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ucm3OCjCyO5m"
      },
      "outputs": [],
      "source": [
        "token_toxicities = []\n",
        "with open('/content/nlp-Text-De-toxification/data/vocab_1/token_toxicities.txt', 'r') as f:\n",
        "    for line in f.readlines():\n",
        "        token_toxicities.append(float(line))\n",
        "token_toxicities = np.array(token_toxicities)\n",
        "token_toxicities = np.maximum(0, np.log(1/(1/token_toxicities-1)))   # log odds ratio\n",
        "\n",
        "# discourage meaningless tokens\n",
        "for tok in ['.', ',', '-']:\n",
        "    token_toxicities[tokenizer.encode(tok)][1] = 3\n",
        "\n",
        "for tok in ['you']:\n",
        "    token_toxicities[tokenizer.encode(tok)][1] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DgLBLEflySLV"
      },
      "outputs": [],
      "source": [
        "def adjust_logits(logits, label=0):\n",
        "    return logits - token_toxicities * 100 * (1 - 2 * label)\n",
        "\n",
        "predictor = MaskedTokenPredictorBert(model, tokenizer, max_len=250, device=device, label=0, contrast_penalty=0.0, logits_postprocessor=adjust_logits)\n",
        "\n",
        "editor = CondBertRewriter(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    device=device,\n",
        "    neg_words=negative_words,\n",
        "    pos_words=positive_words,\n",
        "    word2coef=word2coef,\n",
        "    token_toxicities=token_toxicities,\n",
        "    predictor=predictor,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dYqRJpUJyTnp"
      },
      "outputs": [],
      "source": [
        "chooser = EmbeddingSimilarityChooser(sim_coef=10, tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lb9O5ErxyU8A",
        "outputId": "042c9641-ee6f-4d70-9757-398bde5216c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "you are mistake !\n"
          ]
        }
      ],
      "source": [
        "print(editor.translate('You are idiot!', prnt=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UqGZMbvTyvC7",
        "outputId": "bc9e7b2a-5ed6-43e5-f46e-3a2565f0636b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "you are very beautiful !\n"
          ]
        }
      ],
      "source": [
        "print(editor.replacement_loop('You are stupid!', verbose=False, chooser=chooser, n_tokens=(1, 2, 3), n_top=10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzd-bLjAyxXq",
        "outputId": "f19cd0f0-3b5f-4ad1-af54-15437f14984a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------\n",
            "You still upset that I killed your buddy?\n",
            "--> you still upset that i went after my buddy ?\n",
            "------\n",
            "\n",
            "\n",
            "------\n",
            "Boy, it's... it's funny about f-finding this fucking plane, wasn't it?\n",
            "--> boy , it ' s . . . it ' s funny about f - finding this on the wrong plane , wasn ' t it ?\n",
            "------\n",
            "\n",
            "\n",
            "------\n",
            "You got me started with cooking, mrs.\n",
            "--> \" they got i started with cooking , mrs .\n",
            "------\n",
            "\n",
            "\n",
            "------\n",
            "Oh, I'm so sick of this shit!\n",
            "--> oh , i ' m so not sure any of this stuff !\n",
            "------\n",
            "\n",
            "\n",
            "------\n",
            "You will never drink my piss.\n",
            "--> you will never drink my sway .\n",
            "------\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for example in dataset.sample(5)['reference']:\n",
        "    print(\"------\")\n",
        "    print(example)\n",
        "    print(\"-->\", editor.replacement_loop(example, verbose=False, chooser=chooser, n_tokens=(1, 2, 3), n_top=10))\n",
        "    print(\"------\\n\\n\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0ddec33b8f384e31bb788265e55144df": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f31966c715c746d99f47175e6a57be8f",
              "IPY_MODEL_fea030c8b17f496d9017400c26194008",
              "IPY_MODEL_d363cd73f6ff4aa89d8edea9e35d2e18"
            ],
            "layout": "IPY_MODEL_a17aaab8baca4fefb6101612e1439c6a"
          }
        },
        "1c8e18acf1094b398b38e5eefffca584": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41f95a27a0e042f4a1175be3f034b781": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "67a90ae072d34eb7a7be8d753dff618a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8dd5b67dffdb41769a6c98d56ca94e79": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8ecb0aa4fd21485daf9e8390c1412119": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a17aaab8baca4fefb6101612e1439c6a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae7e9ce9a4614c518ff1fccf87eb8e14": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d363cd73f6ff4aa89d8edea9e35d2e18": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae7e9ce9a4614c518ff1fccf87eb8e14",
            "placeholder": "​",
            "style": "IPY_MODEL_41f95a27a0e042f4a1175be3f034b781",
            "value": " 5/5 [01:27&lt;00:00, 16.52s/it]"
          }
        },
        "f31966c715c746d99f47175e6a57be8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67a90ae072d34eb7a7be8d753dff618a",
            "placeholder": "​",
            "style": "IPY_MODEL_8ecb0aa4fd21485daf9e8390c1412119",
            "value": "100%"
          }
        },
        "fea030c8b17f496d9017400c26194008": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c8e18acf1094b398b38e5eefffca584",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8dd5b67dffdb41769a6c98d56ca94e79",
            "value": 5
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}