# -*- coding: utf-8 -*-
"""make_dataset.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jGD3soIAjcnwd9XtBF1sTL0zRvUFIqa1
"""

import os

repo_dir = "nlp-Text-De-toxification"

if os.path.exists(repo_dir):
    print(f"{repo_dir} already exists. Removing it...\n")
    !rm -r {repo_dir}

# Clone the repository from GitHub
!git clone https://github.com/Goshmar/nlp-Text-De-toxification

! pip install -r nlp-Text-De-toxification/requirements.txt -q

import requests
import zipfile

import pandas as pd
import numpy as np

# Define the paths
with open('/content/nlp-Text-De-toxification/data/raw/original_data_link.txt', 'r') as file:
    dataset_url = file.read().strip()

zip_file_path = "dataset.zip"
csv_file_path, tsv_file_path = "dataset.csv", "filtered.tsv"

# Download the ZIP file
response = requests.get(dataset_url)
if response.status_code == 200:
    with open(zip_file_path, 'wb') as file:
        file.write(response.content)
else:
    print("Attempt failed")
    exit()

with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:
    zip_ref.extractall(".")

dataset = pd.read_csv("filtered.tsv", delimiter='\t')
dataset.to_csv(csv_file_path, index=False)

# ZIP cleaning up
os.remove(zip_file_path)
os.remove(tsv_file_path)

dataset

# Let's prepare a reduced dataset for checking and visualizing the program
dataset_cropped = dataset[["reference", "translation"]].sample(n=200)
dataset_cropped.to_csv('dataset_cropped.csv', index=False)

import sys
sys.path.append('/content/nlp-Text-De-toxification/src/models')

from importlib import reload
import condbert
from condbert import CondBertRewriter
reload(condbert)

import torch
from transformers import BertTokenizer, BertForMaskedLM
import pickle
from tqdm.auto import tqdm, trange

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  # please change it to e.g. 'cuda:0' if you want to use a GPU
device

model_name = 'bert-base-uncased'
tokenizer = BertTokenizer.from_pretrained(model_name)
model = BertForMaskedLM.from_pretrained(model_name)
model.to(device);

from sklearn.linear_model import LogisticRegression
from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer

class NgramSalienceCalculator():
    def __init__(self, tox_corpus, norm_corpus, use_ngrams=False):
        ngrams = (1, 3) if use_ngrams else (1, 1)
        self.vectorizer = CountVectorizer(ngram_range=ngrams)

        tox_count_matrix = self.vectorizer.fit_transform(tox_corpus)
        self.tox_vocab = self.vectorizer.vocabulary_
        self.tox_counts = np.sum(tox_count_matrix, axis=0)

        norm_count_matrix = self.vectorizer.fit_transform(norm_corpus)
        self.norm_vocab = self.vectorizer.vocabulary_
        self.norm_counts = np.sum(norm_count_matrix, axis=0)

    def salience(self, feature, attribute='tox', lmbda=0.5):
        assert attribute in ['tox', 'norm']
        if feature not in self.tox_vocab:
            tox_count = 0.0
        else:
            tox_count = self.tox_counts[0, self.tox_vocab[feature]]

        if feature not in self.norm_vocab:
            norm_count = 0.0
        else:
            norm_count = self.norm_counts[0, self.norm_vocab[feature]]

        if attribute == 'tox':
            return (tox_count + lmbda) / (norm_count + lmbda)
        else:
            return (norm_count + lmbda) / (tox_count + lmbda)

from collections import Counter
c = Counter()

for sentence in tqdm(dataset['reference'] + dataset['translation']):
    for tok in sentence.strip().split():
        c[tok] += 1

print(len(c))

# if we took words with > 1 occurences, vocabulary would be x2 smaller, but we'll survive this size
vocab = {w for w, _ in c.most_common() if _ > 0}
print(len(vocab))

corpus_tox = [' '.join([w if w in vocab else '<unk>' for w in line.strip().split()]) for line in dataset['reference']]
corpus_norm = [' '.join([w if w in vocab else '<unk>' for w in line.strip().split()]) for line in dataset['translation']]

neg_out_name = '/content/nlp-Text-De-toxification/data/external/negative-words.txt'
pos_out_name = '/content/nlp-Text-De-toxification/data/external/positive-words.txt'

threshold = 4
sc = NgramSalienceCalculator(corpus_tox, corpus_norm, False)
seen_grams = set()

with open(neg_out_name, 'w') as neg_out, open(pos_out_name, 'w') as pos_out:
    for gram in set(sc.tox_vocab.keys()).union(set(sc.norm_vocab.keys())):
        if gram not in seen_grams:
            seen_grams.add(gram)
            toxic_salience = sc.salience(gram, attribute='tox')
            polite_salience = sc.salience(gram, attribute='norm')
            if toxic_salience > threshold:
                neg_out.writelines(f'{gram}\n')
            elif polite_salience > threshold:
                pos_out.writelines(f'{gram}\n')

from sklearn.pipeline import make_pipeline
pipe = make_pipeline(CountVectorizer(), LogisticRegression(solver='saga', max_iter=1000))

X_train = corpus_tox + corpus_norm
y_train = [1] * len(corpus_tox) + [0] * len(corpus_norm)
pipe.fit(X_train, y_train);

coefs = pipe[1].coef_[0]
coefs.shape

word2coef = {w: coefs[idx] for w, idx in pipe[0].vocabulary_.items()}

import pickle
with open('/content/nlp-Text-De-toxification/data/interim/word2coef.pkl', 'wb') as f:
    pickle.dump(word2coef, f)

from collections import defaultdict
toxic_counter = defaultdict(lambda: 1)
nontoxic_counter = defaultdict(lambda: 1)

for text in tqdm(corpus_tox):
    for token in tokenizer.encode(text):
        toxic_counter[token] += 1
for text in tqdm(corpus_norm):
    for token in tokenizer.encode(text):
        nontoxic_counter[token] += 1

token_toxicities = [toxic_counter[i] / (nontoxic_counter[i] + toxic_counter[i]) for i in range(len(tokenizer.vocab))]

with open('/content/nlp-Text-De-toxification/data/interim/token_toxicities.txt', 'w') as f:
    for t in token_toxicities:
        f.write(str(t))
        f.write('\n')

